# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
from snowflake.snowpark.context import get_active_session
import plotly.express as px
import re
import ast
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ãƒšãƒ¼ã‚¸è¨­å®šï¼šå¹…åºƒãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ä½¿ç”¨
st.set_page_config(layout="wide")

# ç¾åœ¨ã®Snowflakeã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—
session = get_active_session()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data
def get_databases():
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸€è¦§ã‚’Snowflakeã‹ã‚‰å–å¾—
    return pd.DataFrame({'<Select>'},columns=['DATABASE_NAME'])._append(session.sql("""
        select database_name DATABASE_NAME
        from snowflake.account_usage.databases  
        where deleted is null
        order by 1
    """).toPandas())

@st.cache_data()
def get_table_stats(database_name, schema_name, table_name):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    try:
        stats = session.sql(f"""
            SELECT 
                'Last Updated' as metric,
                TO_CHAR(MAX(LAST_ALTERED), 'YYYY-MM-DD HH24:MI:SS') as value
            FROM {database_name}.information_schema.tables 
            WHERE table_name = '{table_name}'
            AND table_schema = '{schema_name}'
            UNION ALL
            SELECT 
                'Created On',
                TO_CHAR(MIN(CREATED), 'YYYY-MM-DD HH24:MI:SS')
            FROM {database_name}.information_schema.tables 
            WHERE table_name = '{table_name}'
            AND table_schema = '{schema_name}'
            UNION ALL
            SELECT 
                'Storage Size (Bytes)',
                TO_CHAR(SUM(bytes), '999,999,999,999')
            FROM {database_name}.information_schema.tables 
            WHERE table_name = '{table_name}'
            AND table_schema = '{schema_name}'
        """)
        return stats.toPandas()
    except Exception as e:
        st.error(f"çµ±è¨ˆæƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return pd.DataFrame()

# ãƒ†ãƒ¼ãƒ–ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã‚’å–å¾—ã™ã‚‹é–¢æ•°
# @st.cache_data()
def get_table_catalog(databasename):
    df = session.sql ("SELECT distinct COMMENT, table_catalog, table_schema, table_name, table_owner, row_count FROM " + databasename + ".information_schema.tables where table_schema !='INFORMATION_SCHEMA'")
    return df.toPandas()

# ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã‚’è¿½åŠ 
@st.cache_data()
def get_table_access_count(database_name):
    """å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹å›æ•°ã‚’é›†è¨ˆã™ã‚‹é–¢æ•°"""
    try:
        access_counts = session.sql(f"""
            WITH parsed_objects AS (
                SELECT 
                    query_id,
                    f.value:objectDomain::STRING as obj_domain,
                    f.value:objectName::STRING as obj_name
                FROM SNOWFLAKE.ACCOUNT_USAGE.ACCESS_HISTORY,
                TABLE(FLATTEN(direct_objects_accessed)) f
                WHERE QUERY_START_TIME >= DATEADD(month, -1, CURRENT_TIMESTAMP())
            )
            SELECT 
                obj_name as TABLE_FULL_NAME,
                COUNT(DISTINCT query_id) as ACCESS_COUNT
            FROM parsed_objects
            WHERE obj_domain = 'Table'
            AND CONTAINS(obj_name, '{database_name}')
            GROUP BY obj_name
        """).toPandas()
        return access_counts
    except Exception as e:
        st.error(f"ã‚¢ã‚¯ã‚»ã‚¹çµ±è¨ˆã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return pd.DataFrame(columns=['TABLE_FULL_NAME', 'ACCESS_COUNT'])

# ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data()
def get_count(tablename):
    df = session.sql("select count(*) as count_rows from " + tablename)
    df = df.toPandas()
    count = df['COUNT_ROWS'].values[0]
    return format(count, ',')

# ã‚«ãƒ©ãƒ æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data()
def get_column_data(tablename):
    df = session.sql("select TABLE_NAME, COLUMN_NAME, COMMENT from information_schema.columns where table_name= '" +tablename + "'")
    return df.toPandas()

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data()
def get_useraccess(tablename):
    df = session.sql("select user as USER_NAME, name as tablename from " +PARAM_TABLE_ACCESS+ " join (select distinct role, grantee_name as user from SNOWFLAKE.ACCOUNT_USAGE.GRANTS_TO_USERS) user_table on " + PARAM_TABLE_ACCESS+".GRANTEE_NAME = user_table.role where tablename='"+tablename+"';")
    return df.toPandas()

# æ©Ÿå¯†ã‚«ãƒ©ãƒ æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰
@st.cache_data()
def get_sensitive_column(databasename, tablename):
    df = session.sql("select COLUMN_NAME, TAG_NAME, TAG_VALUE from snowflake.account_usage.tag_references where OBJECT_DATABASE = '" + databasename + "' and OBJECT_NAME ='" + tablename + "'")
    return df.toPandas()

# Completeé–¢æ•°ã®å®Ÿè¡Œ
def get_response(session, prompt):
    # cortex.completeã¯roleãŒuserã§ãªã„ã¨å‹•ä½œã—ãªã„ã®ã§æ³¨æ„
    response = session.sql(f'''
    SELECT SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet',
        {prompt},
        {{
            'temperature': 0,
            'top_p': 0
        }});
        ''').to_pandas().iloc[0,0]
    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¾æ›¸å‹ã«å¤‰æ›
    response = ast.literal_eval(response)
    response = response["choices"][0]["messages"]
    return response
    
def get_table_context(table_name, column_data):
    context = f"""
        ãƒ†ãƒ¼ãƒ–ãƒ«åã¯<tableName>"{str(table_name)}"</tableName>ã§ã™ã€‚
        SQLã®ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªã¯ã“ã¡ã‚‰ã§ã™ã€‚<ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª> select * from {str(table_name)} </ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª> 

        ã¾ãŸã€å¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæŒã¤åˆ—æƒ…å ±ã¯<columns>"{column_data}"</columns>ã§ã™ã€‚ 
    """
    return context

def get_system_prompt(table_name, column_data):
    table_context = get_table_context(table_name = table_name, column_data = column_data)
    return GEN_SQL.format(context=table_context)

GEN_SQL = """
ã‚ãªãŸã¯Snowflake SQL ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã—ã¦è¡Œå‹•ã—ã¾ã™ã€‚è³ªå•ã®å›ç­”ã¯æ—¥æœ¬èªã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
ãƒ†ãƒ¼ãƒ–ãƒ«ãŒä¸ãˆã‚‰ã‚Œã‚‹ã®ã§ã€ãƒ†ãƒ¼ãƒ–ãƒ«åã¯ <tableName> ã‚¿ã‚°å†…ã«ã‚ã‚Šã€åˆ—ã¯ <columns> ã‚¿ã‚°å†…ã«ã‚ã‚‹ã®ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚
ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¦‚è¦ã¯ä»¥ä¸‹ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚

{context}

ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¦‚è¦ã‚’èª¬æ˜ã—ã€ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®å„è¡Œã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã«ã©ã®ã‚ˆã†ãªç›¸é–¢ã‚„ç‰¹å¾´ãŒã‚ã‚‹ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸåˆ—ã‚’ç¢ºèªã—åˆ©ç”¨å¯èƒ½ãªæŒ‡æ¨™ã‚’æ•°è¡Œã§å…±æœ‰ã—ã€ç®‡æ¡æ›¸ãã‚’ä½¿ç”¨ã—ã¦åˆ†æä¾‹ã‚’3ã¤ã‚’å¿…ãšæŒ™ã’ã¦ãã ã•ã„ã€‚
ã¾ãŸãªãœãã®åˆ†æä¾‹ãŒåŠ¹æœçš„ãªã®ã‹ã‚‚è©³ç´°ã«èª¬æ˜ã—ã€ã‚µãƒ³ãƒ—ãƒ«ã®SQLã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""

##########################é–‹ç™ºä¸­############################ 
def get_cosine_similarity():
    """
    MARKETPLACE_EMBEDDING_LISTINGSã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    ã€Œè©³ç´°ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    ï¼’ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ VECTOR_COSINE_SIMILARITYã§é¡ä¼¼åº¦æ¤œç´¢
    """
    search_results = session.sql(f"""
        SELECT 
            market.TITLE, 
            market.DESCRIPTION, 
            VECTOR_COSINE_SIMILARITY(catalog.embeddings, market.embeddings) as similarity
        FROM 
            DATA_CATALOG.TABLE_CATALOG.TABLE_CATALOG catalog, 
            DATA_CATALOG.TABLE_CATALOG.MARKETPLACE_EMBEDDING_LISTINGS market
        ORDER BY 
            similarity DESC
        LIMIT 10
        """).collect()
    return search_results
##########################é–‹ç™ºä¸­############################ 

# ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ã‚¿ãƒ–ã®å†…å®¹
st.title("ãƒ†ãƒ¼ãƒ–ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã‚¢ãƒ—ãƒª â„ï¸")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
st.subheader(f"ã‚ˆã†ã“ã  :blue[{str(st.experimental_user.user_name)}] ã•ã‚“")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¸æŠãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³
df_databases = get_databases()
filter_database = st.selectbox('DBã‚’é¸æŠã—ã¦ãã ã•ã„',df_databases['DATABASE_NAME'])

if not '<Select>' in filter_database:
    database_name = filter_database.split(' ')[0].replace('(','').replace(')','')
    
    with st.spinner('ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­'):
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚«ã‚¿ãƒ­ã‚°ã¨ã‚¢ã‚¯ã‚»ã‚¹çµ±è¨ˆã‚’å–å¾—
        table_catalog = get_table_catalog(database_name)
        access_counts = get_table_access_count(database_name)
        
        # 4åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        for index, row in table_catalog.iterrows():
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦é©åˆ‡ãªåˆ—ã«é…ç½®
            current_col = [col1, col2, col3, col4][index % 4]
            with current_col:
                with st.expander("**"+row['TABLE_NAME']+"**", expanded=True):
                    # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å®Œå…¨ãªåå‰ã‚’ä½œæˆ
                    full_table_name = f"{row['TABLE_CATALOG']}.{row['TABLE_SCHEMA']}.{row['TABLE_NAME']}"
                    
                    # ã‚¢ã‚¯ã‚»ã‚¹å›æ•°ã‚’å–å¾—
                    access_count = access_counts[
                        access_counts['TABLE_FULL_NAME'] == full_table_name
                    ]['ACCESS_COUNT'].values[0] if not access_counts.empty and full_table_name in access_counts['TABLE_FULL_NAME'].values else 0
                    
                    # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã¨ã‚¢ã‚¯ã‚»ã‚¹æ•°ã‚’è¡¨ç¤º
                    st.write(row['COMMENT'])
                    
                    # ã‚¢ã‚¯ã‚»ã‚¹æ•°ã®è¡¨ç¤ºã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
                    st.markdown(
                        f"""
                        <div style='
                            background-color: #eef1f6;
                            padding: 8px 15px;
                            border-radius: 5px;
                            margin: 10px 0;
                            display: inline-block;
                            border: 1px solid #e0e4eb;
                        '>
                            <span style='font-size: 0.9em; color: #666;'>ğŸ‘¥ éå»30æ—¥é–“ã®ã‚¢ã‚¯ã‚»ã‚¹æ•°:</span>
                            <span style='font-size: 1.1em; font-weight: bold; margin-left: 8px; color: #2c3e50;'>{access_count}</span>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    key_details = full_table_name
                    get_data_details = st.button("è©³ç´°", key=key_details, type="primary")
                    
            # è©³ç´°æƒ…å ±ã®è¡¨ç¤º
            if get_data_details:
                st.session_state.messages = []
                
                count_rows = get_count(key_details)
                table_parts = key_details.split('.')
                database_name = table_parts[0]
                schema_name = table_parts[1]
                table_name = table_parts[2]

                # ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¦‚è¦è¡¨ç¤º
                with st.expander(str(key_details) + " ã®æ¦‚è¦", expanded=True):                    
                    # è¡Œæ•°è¡¨ç¤º
                    st.success("ãƒ¬ã‚³ãƒ¼ãƒ‰æ•° : " + str(count_rows))

                    # ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
                    st.info("ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆæƒ…å ±")
                    stats_df = get_table_stats(database_name, schema_name, table_name)
                    if not stats_df.empty:
                        st.dataframe(stats_df, use_container_width=True)

                    # ãƒ†ãƒ¼ãƒ–ãƒ«ã®Preview
                    st.info("ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®ã‚«ãƒ©ãƒ åã¨èª¬æ˜")
                    sql = session.sql(f"select * from {key_details} limit 10")
                    st.write(sql)

                # LLM ã‚’ä½¿ã£ãŸåˆ†æ
                with st.expander("LLMã‚’ä½¿ã£ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®è©³ç´°åˆ†æ"):
                    column_data = get_column_data(table_name)
                    prompt = get_system_prompt(table_name, column_data)
                    st.session_state.messages.append({"role": 'user', "content": prompt})

                    response = get_response(session, st.session_state.messages)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.markdown(response)

                # ãƒã‚±ãƒ—ãƒ¬ãƒ‡ãƒ¼ã‚¿ã¨ã®é¡ä¼¼æ¤œç´¢
                with st.expander("ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ã‚¤ã‚¹ã§å½¹ç«‹ã¡ãã†ãªãƒ‡ãƒ¼ã‚¿ä¸Šä½10ä»¶"):
                    results = get_cosine_similarity()
                    st.dataframe(results)